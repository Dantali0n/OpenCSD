% this file is called up by thesis.tex
% content in this file will be fed into the main document

\chapter{Experiments} % top level followed by section, subsection


% ----------------------- paths to graphics ------------------------

% change according to folder and file names
\ifpdf
    \graphicspath{{7/figures/PNG/}{7/figures/PDF/}{7/figures/}}
\else
    \graphicspath{{7/figures/EPS/}{7/figures/}}
\fi


% ----------------------- contents from here ------------------------
% 

\section{Experiment Design}

In this section we describe several experiments to evaluate the performance of
FluffleFS. These experiments can be separated into two categories. Firstly,
microbenchmarks operating on relatively simple reads and writes.
Secondly, isolated applications that likely benefit from offloading
ported to be used by FluffleFS. For each of these applications we reason
about the expected and achieved data movement reduction among other performance
metrics.

For each of the experiments measurements are taken 30 times to account for
variance between measurements. For almost all measurements the mean will
be used alongside minimum and maximum errors bars.

\subsection{Microbenchmarks}

Most of these microbenchmarks serve to compare performance against more
established ZNS supporting filesystems. For these microbenchmarks the popular
F2FS\cite{Lee2015F2FSAN} filesystem is used. Exceptions to these include
evaluating the offloading and concurrent performance of FluffleFS against its
regular performance.

E
Each of these benchmarks is executed on a freshly formatted filesystem each
time due to the inability of FluffleFS to reach \textit{Steady State}. while
F2FS is able to reach steady state a comparison between filesystems in such
substantially different states would be unfair.

\begin{enumerate}
    \item Sequential reads \& writes f2fs vs FluffleFS
    (Linegraph transfer rate MB/s - 64k up until 1g filesizes)
    (Static request size of 512k unless file is smaller)
    \begin{itemize}
        \item Demonstrate what performance can be expected from FluffleFS as
              regular filesystem.
    \end{itemize}
    \item Random reads \& writes f2fs vs FluffleFS
    (Linegraph transfer rate MB/s - 4k, 8k, 16k, 32k, 64k, 128k request sizes)
    (Static file size of 1g, this is to exhaust caches and their effects)
    \begin{itemize}
        \item Demonstrate what performance can be expected from FluffleFS as
              regular filesystem.
    \end{itemize}
    \item Sequential reads \& writes regular vs passthrough kernel
    (Linegraph transfer rate MB/s - 64k up until 1g filesizes)
    (Static request size of 512k unless file is smaller)
    \begin{itemize}
        \item Show performance impact of snapshotting and uBPF.
    \end{itemize}
    \item Sequential reads \& writes concurrently regular \& 1 passthrough 512k
    request size
    (Linegraph, 1, 2, 4, 8 threads, with best performer previous benchmark)
    \begin{itemize}
        \item Demonstrate the passthrough kernel performance is relatively
              unaffected compared to deminishing performace of regular reads
              \& writes for multiple threads. (Proof concurrent access to the
              same file).
    \end{itemize}
\end{enumerate}

\subsection{Applications}

\begin{enumerate}
    \item Offload integer average (read stream kernel)
    \begin{itemize}
        \item Have one thread write append to a file while the another computes
              the integer average for this file do so using both regular access
              and using kernel offloading.
        \item Demonstrate offloading can reduce amount of data transfered
              between host and device significantly with no signifcant
              performance impact.
    \end{itemize}
    \item Offloaded shannon entropy (read stream kernel)
    \begin{itemize}
        \item Go through all files in a directory and determine entropy of first
              512k of each file. Return a list of files with entropy < 6.
        \item Demonstrate that async applications can reduce host load by
              waiting for offloaded tasks (Total CPU time - kernel CPU time)
    \end{itemize}
    \item CSV index generation (write event kernel)
    \begin{itemize}
        \item Generate indexes for a query replicated from TPC-DS at 512k
              intervals.
        \item Demonstrate that async applications can reduce host load by
              waiting for offloaded tasks (Total CPU time - kernel CPU time)
    \end{itemize}
\end{enumerate}

\section{Experimental Setup}

% Machine host, configuration, kernel version, modules and versions,
% software compiler flags

% Use alacritty to prevent performance influence of writing to stdout / stderr


\subsection{Pitfalls}

% ---------------------------------------------------------------------------
% ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------